{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['they', 'room', 'came', 'with', 'said', 'There', 'house', 'into', 'them', 'were', 'Edmund', 'that', 'Lucy']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import FreqDist\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "corpus_root = '/home/willem/Documents/TTV'\n",
    "\n",
    "wordlists = PlaintextCorpusReader(corpus_root, '.*') \n",
    "wordlists.fileids()\n",
    "Narnia = wordlists.words('Narnia')\n",
    "\n",
    "fdist1 = FreqDist(Narnia)\n",
    "#print(fdist1.most_common(10))\n",
    "print(list(set([word for word in Narnia if len(word)>3 and fdist1[word] > 5])))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import CFG\n",
    "from nltk.grammar import FeatureGrammar\n",
    "from nltk.parse import RecursiveDescentParser, FeatureEarleyChartParser, ShiftReduceParser\n",
    "from nltk.parse.generate import generate\n",
    "\n",
    "# Function that works for multiple types of parsers (You are free to use something else if you want.)\n",
    "def check_sentence(parser, sentence):\n",
    "    print(\"--------------------------------------------------\")\n",
    "    print(\"Checking if provided sentence matches the grammar:\")\n",
    "    print(sentence)\n",
    "    if isinstance(sentence, str):\n",
    "        sentence = sentence.split()\n",
    "    tree_found = False\n",
    "    results = parser.parse(sentence)\n",
    "    for tree in results:\n",
    "        tree_found = True\n",
    "        print(tree)\n",
    "    if not tree_found:\n",
    "        print(sentence, \"Does not match the provided grammar.\")\n",
    "    print(\"--------------------------------------------------\")\n",
    "    return tree_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = FeatureGrammar.fromstring(\"\"\"\n",
    "    \n",
    "    # sentences\n",
    "    S -> NP VP\n",
    "    S -> VP\n",
    "    S -> S WHNP\n",
    "    S -> S CC S\n",
    "    SBAR -> WHNP VP\n",
    "    \n",
    "     \n",
    "    # constituents\n",
    "    NP -> Det N\n",
    "    NP -> Det N N\n",
    "    NP -> N N\n",
    "    NP -> NNP\n",
    "    NP -> Adj N\n",
    "    NP -> Det ADJP N\n",
    "    NP -> OP NP\n",
    "    NP -> Pro CC Pro\n",
    "    NP -> Pro\n",
    "    NP -> NN SBAR\n",
    "    NP -> Adv\n",
    "    \n",
    "    VP -> V NP\n",
    "    VP -> V ADVP PP\n",
    "    VP -> V ADJP PP\n",
    "    VP -> V PP\n",
    "    VP -> VBD VP\n",
    "    \n",
    "    PP -> TO NP\n",
    "    PP -> IN NP\n",
    "    PP -> IN IN NP\n",
    "    PP -> Prep NP\n",
    "    PP -> PP PP \n",
    "    \n",
    "    ADVP -> Adv\n",
    "\n",
    "    ADJP -> Adj N\n",
    "    ADJP -> Adj\n",
    "    ADJP -> ADJP Comma ADJP\n",
    "    \n",
    "    WHNP -> Pos N VP\n",
    "    WHNP -> Det\n",
    "    \n",
    "    OP -> Pro Comma\n",
    "    \n",
    "    # lexicon\n",
    "    Det ->  'the' | 'an' | 'this' | 'that'\n",
    "    V -> 'were' | 'sent' | 'is' | 'happened' | 'lived'\n",
    "    VBD -> 'were'\n",
    "    Adj -> 'four' | 'old' | 'ten' | 'nearest' | 'two'\n",
    "    Adv -> 'away' | 'there'\n",
    "    IN -> 'from' | 'during' | 'because' | 'of' | 'in'\n",
    "    TO -> 'to'\n",
    "    N -> 'children' | 'names' | 'war' | 'air-raids' | 'house' | 'professor' \\\n",
    "          | 'story' | 'heart' | 'country' | 'post' | 'office' | 'railway' | 'station' \\\n",
    "          | 'miles'\n",
    "    NNP -> 'london'\n",
    "    NN -> 'something'\n",
    "    Pos -> 'whose'\n",
    "    Pro -> 'peter' | 'susan' | 'edmund' | 'lucy' | 'they' | 'them' | 'he'\n",
    "    CC -> 'and'\n",
    "    Comma -> ','\n",
    "    Prep -> 'about'\n",
    "    \n",
    "\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "#print(check_sentence(cfg_2_parser, 'this story is about something that happened to them'))\n",
    "\n",
    "#for sentence in generate(cfg, n=120):\n",
    "#    print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Checking if provided sentence matches the grammar:\n",
      "there were four children whose names were peter , susan , edmund and lucy\n",
      "(S[]\n",
      "  (S[]\n",
      "    (NP[] (Adv[] there))\n",
      "    (VP[] (V[] were) (NP[] (Adj[] four) (N[] children))))\n",
      "  (WHNP[]\n",
      "    (Pos[] whose)\n",
      "    (N[] names)\n",
      "    (VP[]\n",
      "      (V[] were)\n",
      "      (NP[]\n",
      "        (OP[] (Pro[] peter) (Comma[] ,))\n",
      "        (NP[]\n",
      "          (OP[] (Pro[] susan) (Comma[] ,))\n",
      "          (NP[] (Pro[] edmund) (CC[] and) (Pro[] lucy)))))))\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Checking if provided sentence matches the grammar:\n",
      "he lived ten miles from the nearest railway station and he lived two miles from the nearest post office\n",
      "(S[]\n",
      "  (S[]\n",
      "    (NP[] (Pro[] he))\n",
      "    (VP[]\n",
      "      (V[] lived)\n",
      "      (ADJP[] (Adj[] ten) (N[] miles))\n",
      "      (PP[]\n",
      "        (IN[] from)\n",
      "        (NP[]\n",
      "          (Det[] the)\n",
      "          (ADJP[] (Adj[] nearest) (N[] railway))\n",
      "          (N[] station)))))\n",
      "  (CC[] and)\n",
      "  (S[]\n",
      "    (NP[] (Pro[] he))\n",
      "    (VP[]\n",
      "      (V[] lived)\n",
      "      (ADJP[] (Adj[] two) (N[] miles))\n",
      "      (PP[]\n",
      "        (IN[] from)\n",
      "        (NP[]\n",
      "          (Det[] the)\n",
      "          (ADJP[] (Adj[] nearest) (N[] post))\n",
      "          (N[] office))))))\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg_parser = FeatureEarleyChartParser(cfg)\n",
    "check_sentence(cfg_parser, 'There were four children whose names were Peter , Susan , Edmund and Lucy'.lower())\n",
    "#check_sentence(cfg_parser, 'this story is about something that happened to them'.lower())\n",
    "#check_sentence(cfg_parser, 'they were sent away from London during the war because of the air-raids'.lower())\n",
    "#check_sentence(cfg_parser, 'They were sent to the house of an old Professor'.lower())\n",
    "#check_sentence(cfg_parser, 'The Professor lived in the heart of the country'.lower())\n",
    "check_sentence(cfg_parser, 'he lived ten miles from the nearest railway station and he lived two miles from the nearest post office'.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
